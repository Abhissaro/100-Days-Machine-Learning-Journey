{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2vec From Scratch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5pvdrVu7sPD"
      },
      "source": [
        "## Word2Vec from Scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3QkiSBlD41PB"
      },
      "source": [
        "text = '''Machine learning is the study of computer algorithms that \\\n",
        "improve automatically through experience. It is seen as a \\\n",
        "subset of artificial intelligence. Machine learning algorithms \\\n",
        "build a mathematical model based on sample data, known as \\\n",
        "training data, in order to make predictions or decisions without \\\n",
        "being explicitly programmed to do so. Machine learning algorithms \\\n",
        "are used in a wide variety of applications, such as email filtering \\\n",
        "and computer vision, where it is difficult or infeasible to develop \\\n",
        "conventional algorithms to perform the needed tasks.'''"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-2WIWhK5Fss"
      },
      "source": [
        "### Tokenization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDA6mmJE4-nT"
      },
      "source": [
        "import re\n",
        "\n",
        "def tokenize(text):\n",
        "    pattern = re.compile(r'[A-Za-z]+[\\w^\\']*|[\\w^\\']*[A-Za-z]+[\\w^\\']*')\n",
        "    return pattern.findall(text.lower())\n",
        "  \n",
        "tokens = tokenize(text)\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGFWfSwJ5UVd",
        "outputId": "4df8a70d-418c-4f34-968e-a47fb73960b5"
      },
      "source": [
        "def mapping(tokens):\n",
        "    word_to_id = {}\n",
        "    id_to_word = {}\n",
        "    \n",
        "    for i, token in enumerate(set(tokens)):\n",
        "        word_to_id[token] = i\n",
        "        id_to_word[i] = token\n",
        "    \n",
        "    return word_to_id, id_to_word\n",
        "\n",
        "word_to_id, id_to_word = mapping(tokens)\n",
        "word_to_id"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'a': 19,\n",
              " 'algorithms': 33,\n",
              " 'and': 46,\n",
              " 'applications': 13,\n",
              " 'are': 0,\n",
              " 'artificial': 57,\n",
              " 'as': 23,\n",
              " 'automatically': 32,\n",
              " 'based': 44,\n",
              " 'being': 9,\n",
              " 'build': 4,\n",
              " 'computer': 42,\n",
              " 'conventional': 2,\n",
              " 'data': 14,\n",
              " 'decisions': 8,\n",
              " 'develop': 29,\n",
              " 'difficult': 11,\n",
              " 'do': 26,\n",
              " 'email': 25,\n",
              " 'experience': 12,\n",
              " 'explicitly': 47,\n",
              " 'filtering': 50,\n",
              " 'improve': 27,\n",
              " 'in': 16,\n",
              " 'infeasible': 40,\n",
              " 'intelligence': 6,\n",
              " 'is': 17,\n",
              " 'it': 20,\n",
              " 'known': 10,\n",
              " 'learning': 39,\n",
              " 'machine': 43,\n",
              " 'make': 41,\n",
              " 'mathematical': 53,\n",
              " 'model': 52,\n",
              " 'needed': 51,\n",
              " 'of': 38,\n",
              " 'on': 1,\n",
              " 'or': 5,\n",
              " 'order': 58,\n",
              " 'perform': 28,\n",
              " 'predictions': 34,\n",
              " 'programmed': 59,\n",
              " 'sample': 45,\n",
              " 'seen': 55,\n",
              " 'so': 37,\n",
              " 'study': 30,\n",
              " 'subset': 21,\n",
              " 'such': 22,\n",
              " 'tasks': 31,\n",
              " 'that': 24,\n",
              " 'the': 3,\n",
              " 'through': 36,\n",
              " 'to': 56,\n",
              " 'training': 15,\n",
              " 'used': 48,\n",
              " 'variety': 7,\n",
              " 'vision': 35,\n",
              " 'where': 54,\n",
              " 'wide': 18,\n",
              " 'without': 49}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBKFHxmE5bqV"
      },
      "source": [
        "##Generating Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-ye1-QU5VAv",
        "outputId": "0c3bfe85-1197-4032-f963-fd68cdc0af93"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "\n",
        "def generate_training_data(tokens, word_to_id, window):\n",
        "    X = []\n",
        "    y = []\n",
        "    n_tokens = len(tokens)\n",
        "    \n",
        "    for i in range(n_tokens):\n",
        "        idx = concat(\n",
        "            range(max(0, i - window), i), \n",
        "            range(i, min(n_tokens, i + window + 1))\n",
        "        )\n",
        "        for j in idx:\n",
        "            if i == j:\n",
        "                continue\n",
        "            X.append(one_hot_encode(word_to_id[tokens[i]], len(word_to_id)))\n",
        "            y.append(one_hot_encode(word_to_id[tokens[j]], len(word_to_id)))\n",
        "    \n",
        "    return np.asarray(X), np.asarray(y)\n",
        "\n",
        "def concat(*iterables):\n",
        "    for iterable in iterables:\n",
        "        yield from iterable\n",
        "\n",
        "def one_hot_encode(id, vocab_size):\n",
        "    res = [0] * vocab_size\n",
        "    res[id] = 1\n",
        "    return res\n",
        "X, y = generate_training_data(tokens, word_to_id, 2)\n",
        "print(X.shape,y.shape)\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(330, 60) (330, 60)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl1fYPYX6HvE"
      },
      "source": [
        "## The Embedding Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtP46TGT5zu3"
      },
      "source": [
        "def init_network(vocab_size, n_embedding):\n",
        "    model = {\n",
        "        \"w1\": np.random.randn(vocab_size, n_embedding),\n",
        "        \"w2\": np.random.randn(n_embedding, vocab_size)\n",
        "    }\n",
        "    return model\n",
        "model = init_network(len(word_to_id), 10)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ZdQprzw6Opw"
      },
      "source": [
        "def forward(model, X, return_cache=True):\n",
        "    cache = {}\n",
        "    \n",
        "    cache[\"a1\"] = X @ model[\"w1\"]\n",
        "    cache[\"a2\"] = cache[\"a1\"] @ model[\"w2\"]\n",
        "    cache[\"z\"] = softmax(cache[\"a2\"])\n",
        "    \n",
        "    if not return_cache:\n",
        "        return cache[\"z\"]\n",
        "    return cache\n",
        "def softmax(X):\n",
        "    res = []\n",
        "    for x in X:\n",
        "        exp = np.exp(x)\n",
        "        res.append(exp / exp.sum())\n",
        "    return res"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bt_n8tvQ6Wx4",
        "outputId": "0ec5d912-686b-4b84-8d1b-5dea0569d1fb"
      },
      "source": [
        "(X @ model[\"w1\"]).shape\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(330, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XfvxN2qW6Z06",
        "outputId": "e79d93ba-08d0-4317-9b75-819e49b4e5ad"
      },
      "source": [
        "(X @ model[\"w1\"] @ model[\"w2\"]).shape\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(330, 60)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqwqMLAs6dQ1"
      },
      "source": [
        "def backward(model, X, y, alpha):\n",
        "    cache  = forward(model, X)\n",
        "    da2 = cache[\"z\"] - y\n",
        "    dw2 = cache[\"a1\"].T @ da2\n",
        "    da1 = da2 @ model[\"w2\"].T\n",
        "    dw1 = X.T @ da1\n",
        "    assert(dw2.shape == model[\"w2\"].shape)\n",
        "    assert(dw1.shape == model[\"w1\"].shape)\n",
        "    model[\"w1\"] -= alpha * dw1\n",
        "    model[\"w2\"] -= alpha * dw2\n",
        "    return cross_entropy(cache[\"z\"], y)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqK2EBRy6fhA"
      },
      "source": [
        "def cross_entropy(z, y):\n",
        "    return - np.sum(np.log(z) * y)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "kztSFnRR6n0k",
        "outputId": "bb231987-ae30-4c3f-cfcf-7ec1a5041d30"
      },
      "source": [
        "#model performance\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "plt.style.use(\"seaborn\")\n",
        "\n",
        "n_iter = 50\n",
        "learning_rate = 0.05\n",
        "\n",
        "history = [backward(model, X, y, learning_rate) for _ in range(n_iter)]\n",
        "\n",
        "plt.plot(range(len(history)), history, color=\"skyblue\")\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 576x396 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"329.701875pt\" version=\"1.1\" viewBox=\"0 0 490.04375 329.701875\" width=\"490.04375pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 329.701875 \nL 490.04375 329.701875 \nL 490.04375 0 \nL 0 0 \nz\n\" style=\"fill:#ffffff;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.44375 306.18 \nL 482.84375 306.18 \nL 482.84375 7.2 \nL 36.44375 7.2 \nz\n\" style=\"fill:#eaeaf2;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 56.734659 306.18 \nL 56.734659 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_2\"/>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 51.703125 34.421875 \nQ 51.703125 24.515625 49.828125 17.75 \nQ 47.953125 10.984375 44.703125 6.8125 \nQ 41.453125 2.640625 37.0625 0.828125 \nQ 32.671875 -0.984375 27.6875 -0.984375 \nQ 22.65625 -0.984375 18.3125 0.828125 \nQ 13.96875 2.640625 10.765625 6.78125 \nQ 7.5625 10.9375 5.734375 17.703125 \nQ 3.90625 24.46875 3.90625 34.421875 \nQ 3.90625 44.828125 5.734375 51.640625 \nQ 7.5625 58.453125 10.78125 62.5 \nQ 14.015625 66.546875 18.40625 68.1875 \nQ 22.796875 69.828125 27.984375 69.828125 \nQ 32.90625 69.828125 37.21875 68.1875 \nQ 41.546875 66.546875 44.765625 62.5 \nQ 48 58.453125 49.84375 51.640625 \nQ 51.703125 44.828125 51.703125 34.421875 \nz\nM 42.78125 34.421875 \nQ 42.78125 42.625 41.796875 48.0625 \nQ 40.828125 53.515625 38.921875 56.765625 \nQ 37.015625 60.015625 34.25 61.359375 \nQ 31.5 62.703125 27.984375 62.703125 \nQ 24.265625 62.703125 21.4375 61.328125 \nQ 18.609375 59.96875 16.671875 56.71875 \nQ 14.75 53.46875 13.765625 48.015625 \nQ 12.796875 42.578125 12.796875 34.421875 \nQ 12.796875 26.515625 13.796875 21.09375 \nQ 14.796875 15.671875 16.71875 12.375 \nQ 18.65625 9.078125 21.4375 7.640625 \nQ 24.21875 6.203125 27.78125 6.203125 \nQ 31.25 6.203125 34.03125 7.640625 \nQ 36.8125 9.078125 38.734375 12.375 \nQ 40.671875 15.671875 41.71875 21.09375 \nQ 42.78125 26.515625 42.78125 34.421875 \nz\n\" id=\"LiberationSans-48\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(53.95419 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 139.554696 306.18 \nL 139.554696 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_4\"/>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 7.625 0 \nL 7.625 7.46875 \nL 25.140625 7.46875 \nL 25.140625 60.40625 \nL 9.625 49.3125 \nL 9.625 57.625 \nL 25.875 68.796875 \nL 33.984375 68.796875 \nL 33.984375 7.46875 \nL 50.734375 7.46875 \nL 50.734375 0 \nz\n\" id=\"LiberationSans-49\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(133.993759 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 222.374733 306.18 \nL 222.374733 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_6\"/>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 5.03125 0 \nL 5.03125 6.203125 \nQ 7.515625 11.921875 11.109375 16.28125 \nQ 14.703125 20.65625 18.65625 24.1875 \nQ 22.609375 27.734375 26.484375 30.765625 \nQ 30.375 33.796875 33.5 36.8125 \nQ 36.625 39.84375 38.546875 43.15625 \nQ 40.484375 46.484375 40.484375 50.6875 \nQ 40.484375 53.609375 39.59375 55.828125 \nQ 38.71875 58.0625 37.0625 59.5625 \nQ 35.40625 61.078125 33.078125 61.828125 \nQ 30.765625 62.59375 27.9375 62.59375 \nQ 25.296875 62.59375 22.96875 61.859375 \nQ 20.65625 61.140625 18.84375 59.671875 \nQ 17.046875 58.203125 15.890625 56.03125 \nQ 14.75 53.859375 14.40625 50.984375 \nL 5.421875 51.8125 \nQ 5.859375 55.515625 7.46875 58.78125 \nQ 9.078125 62.0625 11.90625 64.53125 \nQ 14.75 67 18.71875 68.40625 \nQ 22.703125 69.828125 27.9375 69.828125 \nQ 33.0625 69.828125 37.0625 68.609375 \nQ 41.0625 67.390625 43.8125 64.984375 \nQ 46.578125 62.59375 48.046875 59.078125 \nQ 49.515625 55.5625 49.515625 50.984375 \nQ 49.515625 47.515625 48.265625 44.390625 \nQ 47.015625 41.265625 44.9375 38.421875 \nQ 42.875 35.59375 40.140625 32.953125 \nQ 37.40625 30.328125 34.421875 27.8125 \nQ 31.453125 25.296875 28.421875 22.828125 \nQ 25.390625 20.359375 22.71875 17.859375 \nQ 20.0625 15.375 17.96875 12.8125 \nQ 15.875 10.25 14.703125 7.46875 \nL 50.59375 7.46875 \nL 50.59375 0 \nz\n\" id=\"LiberationSans-50\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(216.813796 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 305.19477 306.18 \nL 305.19477 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_8\"/>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <defs>\n       <path d=\"M 51.21875 19 \nQ 51.21875 14.265625 49.671875 10.546875 \nQ 48.140625 6.84375 45.1875 4.265625 \nQ 42.234375 1.703125 37.859375 0.359375 \nQ 33.5 -0.984375 27.875 -0.984375 \nQ 21.484375 -0.984375 17.109375 0.609375 \nQ 12.75 2.203125 9.90625 4.8125 \nQ 7.078125 7.421875 5.65625 10.765625 \nQ 4.25 14.109375 3.8125 17.671875 \nL 12.890625 18.5 \nQ 13.28125 15.765625 14.328125 13.515625 \nQ 15.375 11.28125 17.1875 9.671875 \nQ 19 8.0625 21.625 7.171875 \nQ 24.265625 6.296875 27.875 6.296875 \nQ 34.515625 6.296875 38.296875 9.5625 \nQ 42.09375 12.84375 42.09375 19.28125 \nQ 42.09375 23.09375 40.40625 25.40625 \nQ 38.71875 27.734375 36.203125 29.03125 \nQ 33.6875 30.328125 30.734375 30.765625 \nQ 27.78125 31.203125 25.296875 31.203125 \nL 20.3125 31.203125 \nL 20.3125 38.8125 \nL 25.09375 38.8125 \nQ 27.59375 38.8125 30.265625 39.328125 \nQ 32.953125 39.84375 35.171875 41.1875 \nQ 37.40625 42.53125 38.84375 44.828125 \nQ 40.28125 47.125 40.28125 50.6875 \nQ 40.28125 56.203125 37.03125 59.390625 \nQ 33.796875 62.59375 27.390625 62.59375 \nQ 21.578125 62.59375 17.984375 59.609375 \nQ 14.40625 56.640625 13.8125 51.21875 \nL 4.984375 51.90625 \nQ 5.515625 56.453125 7.46875 59.8125 \nQ 9.421875 63.1875 12.421875 65.40625 \nQ 15.4375 67.625 19.28125 68.71875 \nQ 23.140625 69.828125 27.484375 69.828125 \nQ 33.25 69.828125 37.390625 68.375 \nQ 41.546875 66.9375 44.1875 64.46875 \nQ 46.828125 62.015625 48.0625 58.6875 \nQ 49.3125 55.375 49.3125 51.609375 \nQ 49.3125 48.578125 48.484375 45.9375 \nQ 47.65625 43.3125 45.890625 41.203125 \nQ 44.140625 39.109375 41.421875 37.59375 \nQ 38.71875 36.078125 34.90625 35.296875 \nL 34.90625 35.109375 \nQ 39.0625 34.671875 42.140625 33.21875 \nQ 45.21875 31.78125 47.21875 29.625 \nQ 49.21875 27.484375 50.21875 24.75 \nQ 51.21875 22.015625 51.21875 19 \nz\n\" id=\"LiberationSans-51\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(299.633833 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-51\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 388.014808 306.18 \nL 388.014808 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_10\"/>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <defs>\n       <path d=\"M 43.015625 15.578125 \nL 43.015625 0 \nL 34.71875 0 \nL 34.71875 15.578125 \nL 2.296875 15.578125 \nL 2.296875 22.40625 \nL 33.796875 68.796875 \nL 43.015625 68.796875 \nL 43.015625 22.515625 \nL 52.6875 22.515625 \nL 52.6875 15.578125 \nz\nM 34.71875 58.890625 \nQ 34.625 58.640625 34.234375 57.9375 \nQ 33.84375 57.234375 33.34375 56.34375 \nQ 32.859375 55.46875 32.34375 54.5625 \nQ 31.84375 53.65625 31.453125 53.078125 \nL 13.8125 27.09375 \nQ 13.578125 26.703125 13.109375 26.0625 \nQ 12.640625 25.4375 12.15625 24.78125 \nQ 11.671875 24.125 11.171875 23.484375 \nQ 10.6875 22.859375 10.40625 22.515625 \nL 34.71875 22.515625 \nz\n\" id=\"LiberationSans-52\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(382.45387 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-52\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 470.834845 306.18 \nL 470.834845 7.2 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_12\"/>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <defs>\n       <path d=\"M 51.421875 22.40625 \nQ 51.421875 17.234375 49.859375 12.9375 \nQ 48.296875 8.640625 45.21875 5.53125 \nQ 42.140625 2.4375 37.578125 0.71875 \nQ 33.015625 -0.984375 27 -0.984375 \nQ 21.578125 -0.984375 17.546875 0.28125 \nQ 13.53125 1.5625 10.734375 3.78125 \nQ 7.953125 6 6.3125 8.984375 \nQ 4.6875 11.96875 4 15.375 \nL 12.890625 16.40625 \nQ 13.421875 14.453125 14.390625 12.625 \nQ 15.375 10.796875 17.0625 9.34375 \nQ 18.75 7.90625 21.21875 7.046875 \nQ 23.6875 6.203125 27.203125 6.203125 \nQ 30.609375 6.203125 33.390625 7.25 \nQ 36.1875 8.296875 38.15625 10.34375 \nQ 40.140625 12.40625 41.203125 15.375 \nQ 42.28125 18.359375 42.28125 22.21875 \nQ 42.28125 25.390625 41.25 28.046875 \nQ 40.234375 30.71875 38.328125 32.640625 \nQ 36.421875 34.578125 33.65625 35.640625 \nQ 30.90625 36.71875 27.390625 36.71875 \nQ 25.203125 36.71875 23.34375 36.328125 \nQ 21.484375 35.9375 19.890625 35.25 \nQ 18.3125 34.578125 17.015625 33.671875 \nQ 15.71875 32.765625 14.59375 31.78125 \nL 6 31.78125 \nL 8.296875 68.796875 \nL 47.40625 68.796875 \nL 47.40625 61.328125 \nL 16.3125 61.328125 \nL 14.984375 39.5 \nQ 17.328125 41.3125 20.84375 42.59375 \nQ 24.359375 43.890625 29.203125 43.890625 \nQ 34.328125 43.890625 38.421875 42.328125 \nQ 42.53125 40.765625 45.40625 37.90625 \nQ 48.296875 35.0625 49.859375 31.109375 \nQ 51.421875 27.15625 51.421875 22.40625 \nz\n\" id=\"LiberationSans-53\"/>\n      </defs>\n      <g style=\"fill:#262626;\" transform=\"translate(465.273907 320.426875)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 36.44375 248.031473 \nL 482.84375 248.031473 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_14\"/>\n     <g id=\"text_7\">\n      <!-- 1000 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 251.654911)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"111.230469\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"166.845703\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 36.44375 183.331992 \nL 482.84375 183.331992 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_16\"/>\n     <g id=\"text_8\">\n      <!-- 1500 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 186.95543)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-49\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"111.230469\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"166.845703\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 36.44375 118.632511 \nL 482.84375 118.632511 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_18\"/>\n     <g id=\"text_9\">\n      <!-- 2000 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 122.255949)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"111.230469\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"166.845703\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 36.44375 53.93303 \nL 482.84375 53.93303 \n\" style=\"fill:none;stroke:#ffffff;stroke-linecap:round;\"/>\n     </g>\n     <g id=\"line2d_20\"/>\n     <g id=\"text_10\">\n      <!-- 2500 -->\n      <g style=\"fill:#262626;\" transform=\"translate(7.2 57.556468)scale(0.1 -0.1)\">\n       <use xlink:href=\"#LiberationSans-50\"/>\n       <use x=\"55.615234\" xlink:href=\"#LiberationSans-53\"/>\n       <use x=\"111.230469\" xlink:href=\"#LiberationSans-48\"/>\n       <use x=\"166.845703\" xlink:href=\"#LiberationSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_21\">\n    <path clip-path=\"url(#p1d5f89cb05)\" d=\"M 56.734659 20.79 \nL 65.016663 146.377175 \nL 73.298667 193.719858 \nL 81.58067 213.164313 \nL 89.862674 225.103233 \nL 98.144678 233.818804 \nL 106.426681 240.724158 \nL 114.708685 246.480349 \nL 122.990689 251.463989 \nL 131.272692 255.876275 \nL 139.554696 259.841649 \nL 147.8367 263.375828 \nL 156.118704 266.544986 \nL 164.400707 269.171133 \nL 172.682711 271.731646 \nL 180.964715 273.602757 \nL 189.246718 275.881833 \nL 197.528722 277.425449 \nL 205.810726 279.443949 \nL 214.09273 280.618794 \nL 222.374733 282.401928 \nL 230.656737 283.385304 \nL 238.938741 284.693574 \nL 247.220744 285.305118 \nL 255.502748 286.245197 \nL 263.784752 286.853516 \nL 272.066756 287.012477 \nL 280.348759 288.250645 \nL 288.630763 288.53956 \nL 296.912767 289.320172 \nL 305.19477 289.163133 \nL 313.476774 290.105956 \nL 321.758778 290.056795 \nL 330.040782 290.488599 \nL 338.322785 289.817155 \nL 346.604789 290.95443 \nL 354.886793 290.737536 \nL 363.168796 291.348153 \nL 371.4508 290.713566 \nL 379.732804 291.749717 \nL 388.014808 291.435258 \nL 396.296811 291.838359 \nL 404.578815 290.740695 \nL 412.860819 292.216033 \nL 421.142822 291.710457 \nL 429.424826 292.223858 \nL 437.70683 291.040169 \nL 445.988833 292.59 \nL 454.270837 292.307473 \nL 462.552841 292.487978 \n\" style=\"fill:none;stroke:#87ceeb;stroke-linecap:round;stroke-width:1.75;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.44375 306.18 \nL 36.44375 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 482.84375 306.18 \nL 482.84375 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 36.44375 306.18 \nL 482.84375 306.18 \n\" style=\"fill:none;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 36.44375 7.2 \nL 482.84375 7.2 \n\" style=\"fill:none;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1d5f89cb05\">\n   <rect height=\"298.98\" width=\"446.4\" x=\"36.44375\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQWSxbXW6yqJ",
        "outputId": "41c64bc3-8557-4d56-bfb3-da36295765e7"
      },
      "source": [
        "learning = one_hot_encode(word_to_id[\"learning\"], len(word_to_id))\n",
        "result = forward(model, [learning], return_cache=False)[0]\n",
        "\n",
        "for word in (id_to_word[id] for id in np.argsort(result)[::-1]):\n",
        "    print(word)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "machine\n",
            "algorithms\n",
            "so\n",
            "intelligence\n",
            "build\n",
            "are\n",
            "the\n",
            "used\n",
            "is\n",
            "learning\n",
            "infeasible\n",
            "computer\n",
            "order\n",
            "conventional\n",
            "to\n",
            "do\n",
            "artificial\n",
            "perform\n",
            "training\n",
            "a\n",
            "subset\n",
            "needed\n",
            "develop\n",
            "wide\n",
            "difficult\n",
            "it\n",
            "predictions\n",
            "in\n",
            "programmed\n",
            "improve\n",
            "that\n",
            "automatically\n",
            "study\n",
            "variety\n",
            "of\n",
            "seen\n",
            "applications\n",
            "data\n",
            "where\n",
            "experience\n",
            "tasks\n",
            "without\n",
            "make\n",
            "model\n",
            "sample\n",
            "vision\n",
            "such\n",
            "through\n",
            "explicitly\n",
            "mathematical\n",
            "or\n",
            "decisions\n",
            "and\n",
            "based\n",
            "email\n",
            "known\n",
            "on\n",
            "as\n",
            "being\n",
            "filtering\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFch6Snx68VU"
      },
      "source": [
        "def get_embedding(model, word):\n",
        "    try:\n",
        "        idx = word_to_id[word]\n",
        "    except KeyError:\n",
        "        print(\"`word` not in corpus\")\n",
        "    one_hot = one_hot_encode(idx, len(word_to_id))\n",
        "    return forward(model, one_hot)[\"a1\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqYl2A3U7JSR",
        "outputId": "1b24a077-ba61-4ee6-d9b7-a9c53c27c38b"
      },
      "source": [
        "get_embedding(model, \"learning\")\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.74289419, -1.49039724, -0.19076983,  1.07908429,  1.1379953 ,\n",
              "       -0.65234609, -0.74105042,  1.89446241,  0.01030275,  0.33573272])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    }
  ]
}